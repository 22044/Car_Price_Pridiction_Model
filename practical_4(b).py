# -*- coding: utf-8 -*-
"""Practical_4(b).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZHgwf3S3sgF5RrYDu1aw_M9KjEaFd_t0

### Regression

### Car Price Prediction Problem
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df=pd.read_csv("/content/drive/MyDrive/dataset/car_data.csv")

df

df.shape

df.columns

"""### Swift Desire - 2016 model -76000 - Petrol - Individual - 1000000 ------ Preedict price --250000 ---- 800000 ---  Outlier

"""

df.head()

df.info() # we can Get Types Of Columns

df.describe()

df.isnull().sum() # to describe null values

df['car_age']=2021-df['Year']   # to get the Age of Car :-    df(name to be given to new column)=(current year-year of manufactured)

df.head()

# to delete the column from Dataset
df.drop('Year',axis=1,inplace=True)
df.head()

plt.figure(figsize=(15,5))
plt.subplot(1,5,1)          #subplot( m , n , p ) divides the current figure into an m -by- n grid and creates axes in the position specified by p 
sns.countplot(df['Fuel_Type'])

import warnings
warnings.filterwarnings('ignore')

plt.figure(figsize=(15,5))
plt.subplot(1,5,1)
sns.countplot(df['Fuel_Type']) # countplot() method is used to Show the counts of observations in each categorical bin using bars.

plt.figure(figsize=(25,5))
plt.subplot(1,5,1)                #plt.subplot(size1,size2,no1)
sns.boxplot(df['Selling_Price'])  #library.boxplot(dataframe['value'])

plt.subplot(1,5,2)
sns.boxplot(df['Present_Price'])

plt.subplot(1,5,3)
sns.boxplot(df['Kms_Driven'])

plt.subplot(1,5,4)
sns.boxplot(df['car_age'])

df.corr()    # dataframe.correlation

plt.figure(figsize=(12,8))
sns.heatmap(df.corr(),annot=True, cmap='viridis')  
# annot= Annotations Which is used to to describe corelation ex(0.029,0.08) are such annotations
# cmap= Colour map

# Cmap Types:_
 
#supported values are 'Accent', 'Accent_r', 
#'Blues', 'Blues_r', 'BrBG', 'BrBG_r', 'BuGn',
# 'BuGn_r', 'BuPu', 'BuPu_r', 'CMRmap', 'CMRmap_r',
# 'Dark2', 'Dark2_r', 'GnBu', 'GnBu_r', 'Greens', 'Greens_r',
# 'Greys', 'Greys_r', 'OrRd', 'OrRd_r', 'Oranges', 'Oranges_r',
# 'PRGn', 'PRGn_r', 'Paired', 'Paired_r', 'Pastel1', 'Pastel1_r', 
#'Pastel2', 'Pastel2_r', 'PiYG', 'PiYG_r', 'PuBu', 'PuBuGn', 'PuBuGn_r',
# 'PuBu_r', 'PuOr', 'PuOr_r', 'PuRd', 'PuRd_r', 'Purples',
# 'Purples_r', 'RdBu', 'RdBu_r', 'RdGy', 'RdGy_r', 'RdPu', 'RdPu_r', 
#'RdYlBu', 'RdYlBu_r', 'RdYlGn', 'RdYlGn_r', 'Reds', 'Reds_r', 
#'Set1', 'Set1_r', 'Set2', 'Set2_r', 'Set3', 'Set3_r', 'Spectral',
# 'Spectral_r', 'Wistia', 'Wistia_r', 'YlGn', 'YlGnBu', 'YlGnBu_r'
#, 'YlGn_r', 'YlOrBr', 'YlOrBr_r', 'YlOrRd', 'YlOrRd_r', 'afmhot',
# 'afmhot_r', 'autumn', 'autumn_r', 'binary', 'binary_r', 'bone', 'bone_r',
# 'brg', 'brg_r', 'bwr', 'bwr_r', 'cividis', 'cividis_r', 'cool', 'cool_r', 
#'coolwarm', 'coolwarm_r', 'copper', 'copper_r', 'crest', 'crest_r', 'cubehelix',
# 'cubehelix_r', 'flag', 'flag_r', 'flare', 'flare_r', 'gist_earth', 'gist_earth_r',
# 'gist_gray', 'gist_gray_r', 'gist_heat', 'gist_heat_r', 'gist_ncar', 'gist_ncar_r',
# 'gist_rainbow', 'gist_rainbow_r', 'gist_stern', 'gist_stern_r',
# 'gist_yarg', 'gist_yarg_r', 'gnuplot', 'gnuplot2', 'gnuplot2_r', 
#'gnuplot_r', 'gray', 'gray_r', 'hot', 'hot_r', 'hsv', 'hsv_r', 
#'icefire', 'icefire_r', 'inferno', 'inferno_r', 'jet', 'jet_r', 'ma...

df.drop('Car_Name', axis=1,inplace=True)    #axis=1 :Column , axis=0 :Row
print(df.shape)
df.head()

"""### Apply OneHot Encorder
### get_dummis
"""

df = pd.get_dummies(df, drop_first=True)  # to remove the Repeated Values or same Row Or Columns

df.shape

df.head()

"""### Data Preprocessing
### splitting dataset into input nd Output
"""

x=df.iloc[:,1:].values  # starting from 1 up to end
y=df.iloc[:,0].values

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3, random_state=0)

x_train.shape,x_test.shape,y_train.shape,y_test.shape

"""Feature Scaling"""

x_train

y_train

from sklearn.preprocessing import MinMaxScaler # or Standard Scalar
sc1 = MinMaxScaler()
x_train =sc1.fit_transform(x_train)
x_test =sc1.fit_transform(x_test)

x_train

y_train

"""### Linear Regression """

from sklearn.linear_model import LinearRegression
model=LinearRegression()
model.fit(x_train,y_train)

y_pred=model.predict(x_test)

result_data=pd.DataFrame()
result_data['Actual_Car_Price']=y_test
result_data['Predict_Car_Price']=y_pred
result_data

plt.plot(result_data['Actual_Car_Price'], label='Actual Price')
plt.plot(result_data['Predict_Car_Price'],label='Predicted Price')
plt.title("Actual and Prdited Car Price Comparision")
plt.legend()
plt.show()

from sklearn.metrics import r2_score
r2_score(y_test, y_pred)*100

"""### Classification"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

import warnings
warnings.filterwarnings("ignore")

data=pd.read_csv("/content/drive/MyDrive/dataset/heart.csv")

data.head()

data.duplicated()

data[data.duplicated()]

data.drop_duplicates(inplace=True)

data.shape

print(f"my data is having {data.shape[0]} rows and {data.shape[1]} columns")

data.columns

data.corr()

plt.figure(figsize=(12,8))
sns.heatmap(data.corr(),annot=True)

x=data.sex.value_counts() # to count value from columns

print(f"no of male in dataset={x[0]} and number of female={x[1]}")      #  f=formatting

sns.countplot(data['sex'])
plt.show()

plt.figure(figsize=(15,5))
plt.subplot(1,5,1)
sns.countplot(data['cp'])

"""#### If count Values of multiple class """

data.isnull().sum()

plt.figure(figsize=(20,10))
sns.boxplot(x=data['restecg'],y=data['age'])
plt.show()

data.head()

x=data.iloc[:,:-1].values
y=data.iloc[:,-1].values

x.shape

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=0)
x_train.shape,x_test.shape,y_train.shape,y_test.shape

from sklearn.preprocessing import StandardScaler
sc=StandardScaler()
x_train =sc1.fit_transform(x_train)
x_test =sc1.fit_transform(x_test)

from sklearn.linear_model import LogisticRegression
lr=LogisticRegression()
lr.fit(x_train,y_train)

y_pred=lr.predict(x_test)

data_actual_pred=pd.DataFrame()

data_actual_pred['Actual']=y_test
data_actual_pred['Pred']=y_pred
data_actual_pred

plt.plot(data_actual_pred['Actual'], label='Actual')
plt.plot(data_actual_pred['Pred'],label='Pred')
plt.title("Actual and Prdited")
plt.legend()
plt.show()

from sklearn.metrics import r2_score
r2_score(y_test, y_pred)*100

